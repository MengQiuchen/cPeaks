{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "722eda82",
   "metadata": {},
   "source": [
    "## train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84c41456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from scbasset import scBasset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "426f0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定 Python 的随机数种子\n",
    "random.seed(2023)\n",
    "\n",
    "# 固定 Numpy 的随机数种子\n",
    "np.random.seed(2023)\n",
    "\n",
    "# 固定 PyTorch 的随机数种子\n",
    "torch.manual_seed(2023)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(2023)\n",
    "    torch.cuda.manual_seed_all(2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2a85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d969c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = scBasset(n_cells=2)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0c4b911",
   "metadata": {},
   "source": [
    "### data procession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "346ceb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(pos_file, neg_file):\n",
    "    # 读取正样本和负样本文件\n",
    "    pos_data,neg_data = [],[]\n",
    "    with open(pos_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if not line.startswith('<'):\n",
    "                pos_data.append(line.strip())\n",
    "    with open(neg_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if not line.startswith('<'):\n",
    "                neg_data.append(line.strip())\n",
    "\n",
    "    # 将所有序列合并为一个列表\n",
    "    all_data = pos_data + neg_data\n",
    "\n",
    "    # 初始化onehot编码和填充的结果列表\n",
    "    onehot_data = []\n",
    "    padded_data = []\n",
    "    label = [1]*len(pos_data)+[0]*len(neg_data)\n",
    "#     print(label)\n",
    "    # 对每个序列进行处理\n",
    "    for seq in tqdm(all_data):\n",
    "        # 将碱基序列转换为数字编码，A: 0, C: 1, G: 2, T: 3, N: 4\n",
    "        num_seq = [0 if base == 'A' else 1 if base == 'C' else 2 if base == 'G' else 3 if base == 'T' else 4 for base in seq]\n",
    "\n",
    "        # 进行onehot编码\n",
    "        onehot_seq = torch.zeros((5, len(num_seq)))\n",
    "        for i, num in enumerate(num_seq):\n",
    "            onehot_seq[num, i] = 1\n",
    "        \n",
    "        onehot_seq = onehot_seq[:4,:]\n",
    "        # 统一序列长度为2000，并进行填充\n",
    "        if len(num_seq) >= 2000:\n",
    "            padded_seq = onehot_seq[:, :2000]\n",
    "        else:\n",
    "            padded_seq = torch.zeros((4, 2000))\n",
    "            padded_seq[:, :len(num_seq)] = onehot_seq\n",
    "\n",
    "        # 将onehot编码和填充后的序列添加到结果列表中\n",
    "        onehot_data.append(onehot_seq)\n",
    "        padded_data.append(padded_seq)\n",
    "\n",
    "    # 将结果列表转换为PyTorch张量，并返回\n",
    "    \n",
    "    return torch.stack(padded_data),torch.tensor(np.array(label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2105f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_data('data/negatives.fa','data/positives.fa')\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec8ac126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32985, 8247)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=4,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,num_workers=4,pin_memory=True)\n",
    "len(train_loader),len(test_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67660f00",
   "metadata": {},
   "source": [
    "## train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca77354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|                                                                                | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4690, Acc: 0.8355, Precision: 0.8425, Recall: 0.8355, F1: 0.8359, AUC: 0.8390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 20%|█████████████▌                                                      | 1/5 [18:19<1:13:18, 1099.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4568, Acc: 0.8483, Precision: 0.8567, Recall: 0.8483, F1: 0.8478, AUC: 0.8484\n",
      "Train Loss: 0.4429, Acc: 0.8637, Precision: 0.8697, Recall: 0.8637, F1: 0.8640, AUC: 0.8671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 40%|████████████████████████████                                          | 2/5 [36:36<54:54, 1098.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4405, Acc: 0.8662, Precision: 0.8713, Recall: 0.8662, F1: 0.8660, AUC: 0.8662\n",
      "Train Loss: 0.4342, Acc: 0.8731, Precision: 0.8787, Recall: 0.8731, F1: 0.8734, AUC: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 60%|██████████████████████████████████████████                            | 3/5 [54:48<36:30, 1095.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4321, Acc: 0.8750, Precision: 0.8784, Recall: 0.8750, F1: 0.8750, AUC: 0.8750\n",
      "Train Loss: 0.4276, Acc: 0.8803, Precision: 0.8856, Recall: 0.8803, F1: 0.8806, AUC: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      " 80%|██████████████████████████████████████████████████████▍             | 4/5 [1:12:52<18:10, 1090.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4309, Acc: 0.8761, Precision: 0.8807, Recall: 0.8761, F1: 0.8760, AUC: 0.8761\n",
      "Train Loss: 0.4215, Acc: 0.8870, Precision: 0.8919, Recall: 0.8870, F1: 0.8873, AUC: 0.8899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 5/5 [1:30:52<00:00, 1090.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.4282, Acc: 0.8792, Precision: 0.8826, Recall: 0.8792, F1: 0.8792, AUC: 0.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from train import train\n",
    "from train import test\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "train_res = []\n",
    "test_res = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_res.append(train(model, train_loader, optimizer, criterion, device))\n",
    "    test_res.append(test(model, test_loader, criterion, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "add8eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'epoch5_20230419.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
